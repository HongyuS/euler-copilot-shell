"""
API é…ç½®éªŒè¯åŠŸèƒ½æ¼”ç¤º

ç®€å•æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„éªŒè¯åŠŸèƒ½ã€‚
ä½¿ç”¨æ–¹æ³•: source .venv/bin/activate && PYTHONPATH=src python tests/app/deployment/test_validate_llm_config.py
"""

import asyncio
import sys
from typing import Any

from app.deployment.models import DeploymentConfig, EmbeddingConfig, LLMConfig


def _output(message: str = "") -> None:
    """è¾“å‡ºæ¶ˆæ¯åˆ°æ ‡å‡†è¾“å‡º"""
    sys.stdout.write(f"{message}\n")
    sys.stdout.flush()


def _output_llm_validation_info(llm_info: dict[str, Any]) -> None:
    """è¾“å‡º LLM éªŒè¯ä¿¡æ¯"""
    _output(f"   ğŸ“± LLM: {llm_info['message']}")

    if llm_info.get("supports_function_call"):
        _output("   ğŸ”§ Function Call: âœ… æ”¯æŒ")
        if "function_call_info" in llm_info:
            format_type = llm_info["function_call_info"].get("format", "unknown")
            _output(f"   ğŸ“‹ æ”¯æŒæ ¼å¼: {format_type}")
    else:
        _output("   ğŸ”§ Function Call: âŒ ä¸æ”¯æŒ")

    if "available_models" in llm_info:
        models = llm_info["available_models"][:3]
        _output(f"   ğŸ“¦ å¯ç”¨æ¨¡å‹ç¤ºä¾‹: {', '.join(models)}")


def _output_embedding_validation_info(embed_info: dict[str, Any]) -> None:
    """è¾“å‡º Embedding éªŒè¯ä¿¡æ¯"""
    _output(f"   ğŸ”¢ Embedding: {embed_info['message']}")
    if "dimension" in embed_info:
        _output(f"   ğŸ“ å‘é‡ç»´åº¦: {embed_info['dimension']}")


async def main() -> None:
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    _output("ğŸ”§ API é…ç½®éªŒè¯æ¼”ç¤º")
    _output("=" * 40)

    config = DeploymentConfig(
        server_ip="127.0.0.1",
        deployment_mode="light",
        llm=LLMConfig(
            endpoint="http://127.0.0.1:1234/v1",
            api_key="lm-studio",
            model="qwen/qwen3-30b-a3b-2507",
            max_tokens=4096,
            temperature=0.7,
            request_timeout=30,
        ),
        embedding=EmbeddingConfig(
            type="openai",
            endpoint="http://127.0.0.1:1234/v1",
            api_key="lm-studio",
            model="text-embedding-bge-m3",
        ),
    )

    _output("ğŸ“‹ æ­¥éª¤ 1: åŸºç¡€å­—æ®µéªŒè¯")
    is_valid, errors = config.validate()
    if not is_valid:
        _output("âŒ åŸºç¡€éªŒè¯å¤±è´¥:")
        for error in errors:
            _output(f"   â€¢ {error}")
        return
    _output("âœ… åŸºç¡€éªŒè¯é€šè¿‡")

    _output("\nğŸŒ æ­¥éª¤ 2: API è¿æ¥æ€§éªŒè¯")
    _output("âš ï¸  æ³¨æ„: éœ€è¦æœ‰æ•ˆçš„ API å¯†é’¥æ‰èƒ½é€šè¿‡æ­¤æ­¥éª¤")
    try:
        # åˆ†åˆ«éªŒè¯ LLM å’Œ Embedding é…ç½®
        llm_valid, llm_msg, llm_info = await config.validate_llm_connectivity()
        embed_valid, embed_msg, embed_info = await config.validate_embedding_connectivity()

        api_valid = llm_valid and embed_valid
        api_errors = []

        if not llm_valid:
            api_errors.append(f"LLM éªŒè¯å¤±è´¥: {llm_msg}")
        if not embed_valid:
            api_errors.append(f"Embedding éªŒè¯å¤±è´¥: {embed_msg}")

        validation_info = {
            "llm": {
                "valid": llm_valid,
                "message": llm_msg,
                **llm_info,
            },
            "embedding": {
                "valid": embed_valid,
                "message": embed_msg,
                **embed_info,
            },
        }

        if not api_valid:
            _output("âŒ API éªŒè¯å¤±è´¥:")
            for error in api_errors:
                _output(f"   â€¢ {error}")
            return

        _output("âœ… API éªŒè¯æˆåŠŸ!")
        if "llm" in validation_info:
            _output_llm_validation_info(validation_info["llm"])
        if "embedding" in validation_info:
            _output_embedding_validation_info(validation_info["embedding"])

    except (ConnectionError, TimeoutError, ValueError) as e:
        _output(f"âš ï¸  éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {e}")
        _output("ğŸ’¡ é€šå¸¸æ˜¯ç½‘ç»œè¿æ¥æˆ– API å¯†é’¥é—®é¢˜")


if __name__ == "__main__":
    _output("ğŸš€ å¼€å§‹æ¼”ç¤º...")
    _output("ğŸ’¡ è¿è¡Œæ–¹æ³•: ")
    _output("ğŸ’¡ source .venv/bin/activate && PYTHONPATH=src python tests/app/deployment/test_validate_llm_config.py")
    _output()

    asyncio.run(main())

    _output("\n" + "=" * 40)
    _output("ğŸ“ éªŒè¯åŠŸèƒ½ç‰¹ç‚¹:")
    _output("âœ“ API è¿æ¥æ€§æµ‹è¯•")
    _output("âœ“ æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥")
    _output("âœ“ Function Call æ”¯æŒæ£€æµ‹")
    _output("âœ“ Embedding å‘é‡ç»´åº¦éªŒè¯")
    _output("âœ“ æ”¯æŒ OpenAI å’Œå…¼å®¹ API")
