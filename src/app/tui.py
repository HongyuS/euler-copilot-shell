"""åŸºäº Textual çš„ TUI åº”ç”¨"""

from __future__ import annotations

import asyncio
from typing import TYPE_CHECKING, Any, ClassVar, NamedTuple, cast

from textual import on
from textual.app import App, ComposeResult
from textual.binding import Binding, BindingType
from textual.containers import Container
from textual.message import Message
from textual.widgets import Footer, Input, Markdown, Static

from __version__ import __version__
from app.dialogs import AgentSelectionDialog, BackendRequiredDialog, ExitDialog
from app.mcp_widgets import MCPConfirmResult, MCPConfirmWidget, MCPParameterResult, MCPParameterWidget
from app.settings import SettingsScreen
from app.tui_header import OIHeader
from app.tui_mcp_handler import TUIMCPEventHandler
from backend.factory import BackendFactory
from backend.hermes import HermesChatClient
from backend.hermes.mcp_helpers import (
    MCPTags,
    extract_mcp_tag,
    format_error_message,
    is_final_mcp_message,
    is_mcp_message,
)
from config import ConfigManager
from config.model import Backend
from i18n.manager import _
from log.manager import get_logger, log_exception
from tool.command_processor import process_command
from tool.validators import APIValidator, validate_oi_connection

if TYPE_CHECKING:
    from textual.events import Key as KeyEvent
    from textual.visual import VisualType

    from backend.base import LLMClientBase


class ContentChunkParams(NamedTuple):
    """å†…å®¹å—å¤„ç†å‚æ•°"""

    content: str
    is_llm_output: bool
    current_content: str
    is_first_content: bool


class FocusableContainer(Container):
    """å¯èšç„¦çš„å®¹å™¨ï¼Œç”¨äºæ¥æ”¶é”®ç›˜äº‹ä»¶å¤„ç†æ»šåŠ¨"""

    def __init__(self, *args, **kwargs) -> None:  # noqa: ANN002, ANN003
        """åˆå§‹åŒ–å¯èšç„¦çš„å®¹å™¨"""
        super().__init__(*args, **kwargs)
        # è®¾ç½®ä¸ºå¯èšç„¦
        self.can_focus = True

    def on_key(self, event: KeyEvent) -> None:
        """å¤„ç†é”®ç›˜äº‹ä»¶"""
        key_handled = True

        if event.key == "up":
            # å‘ä¸Šæ»šåŠ¨
            self.scroll_up()
        elif event.key == "down":
            # å‘ä¸‹æ»šåŠ¨
            self.scroll_down()
        elif event.key == "page_up":
            # å‘ä¸Šç¿»é¡µ
            for _ in range(10):  # æ¨¡æ‹Ÿç¿»é¡µæ•ˆæœ
                self.scroll_up()
        elif event.key == "page_down":
            # å‘ä¸‹ç¿»é¡µ
            for _ in range(10):  # æ¨¡æ‹Ÿç¿»é¡µæ•ˆæœ
                self.scroll_down()
        elif event.key == "home":
            # æ»šåŠ¨åˆ°é¡¶éƒ¨
            self.scroll_home()
        elif event.key == "end":
            # æ»šåŠ¨åˆ°åº•éƒ¨
            self.scroll_end()
        else:
            # å…¶ä»–æŒ‰é”®ä¸å¤„ç†
            key_handled = False
            return

        # åªæœ‰å½“æˆ‘ä»¬å¤„ç†äº†æŒ‰é”®æ—¶ï¼Œæ‰é˜»æ­¢äº‹ä»¶ä¼ é€’
        if key_handled:
            event.prevent_default()
            event.stop()
            # ç¡®ä¿è§†å›¾æ›´æ–°
            self.refresh()


class OutputLine(Static):
    """è¾“å‡ºè¡Œç»„ä»¶"""

    def __init__(self, text: str = "", *, command: bool = False) -> None:
        """åˆå§‹åŒ–è¾“å‡ºè¡Œç»„ä»¶"""
        # ç¦ç”¨å¯Œæ–‡æœ¬æ ‡è®°è§£æï¼Œé˜²æ­¢LLMè¾“å‡ºä¸­çš„ç‰¹æ®Šå­—ç¬¦å¯¼è‡´æ¸²æŸ“é”™è¯¯
        super().__init__(text, markup=False)
        if command:
            self.add_class("command-line")
        self.text_content = text
        self.can_focus = True

    def action_copy(self) -> None:
        """å¤åˆ¶å†…å®¹åˆ°å‰ªè´´æ¿"""
        selection = self.text_selection
        if selection is not None:
            extracted = self.get_selection(selection)
            if extracted:
                selected_text, _ = extracted
                if selected_text:
                    self.app.copy_to_clipboard(selected_text)
                    return
        if self.text_content:
            self.app.copy_to_clipboard(self.text_content)

    def update(self, content: VisualType = "", *, layout: bool = True) -> None:
        """æ›´æ–°ç»„ä»¶å†…å®¹ï¼Œç¡®ä¿ç¦ç”¨å¯Œæ–‡æœ¬æ ‡è®°è§£æ"""
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæ›´æ–°å†…éƒ¨å­˜å‚¨çš„æ–‡æœ¬å†…å®¹
        if isinstance(content, str):
            self.text_content = content
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è¿›è¡Œå®é™…æ›´æ–°
        super().update(content, layout=layout)

    def get_content(self) -> str:
        """è·å–ç»„ä»¶å†…å®¹çš„çº¯æ–‡æœ¬è¡¨ç¤º"""
        return self.text_content


class MarkdownOutput(Markdown):
    """Markdown è¾“å‡ºç»„ä»¶"""

    def __init__(self, markdown_content: str = "") -> None:
        """åˆå§‹åŒ– Markdown è¾“å‡ºç»„ä»¶"""
        super().__init__(markdown_content)
        self.current_content = markdown_content
        self.add_class("llm-output")
        self.can_focus = True

    def action_copy(self) -> None:
        """å¤åˆ¶å†…å®¹åˆ°å‰ªè´´æ¿"""
        selection = self.text_selection
        if selection is not None:
            extracted = self.get_selection(selection)
            if extracted:
                selected_text, _ = extracted
                if selected_text:
                    self.app.copy_to_clipboard(selected_text)
                    return
        if self.current_content:
            self.app.copy_to_clipboard(self.current_content)

    def update_markdown(self, markdown_content: str) -> None:
        """æ›´æ–° Markdown å†…å®¹"""
        self.current_content = markdown_content
        self.update(markdown_content)

    def get_content(self) -> str:
        """è·å–å½“å‰ Markdown åŸå§‹å†…å®¹"""
        return self.current_content


class ProgressOutputLine(MarkdownOutput):
    """å¯æ›¿æ¢çš„è¿›åº¦è¾“å‡ºè¡Œç»„ä»¶ï¼Œç”¨äº MCP å·¥å…·è¿›åº¦æ˜¾ç¤º"""

    def __init__(self, markdown_content: str = "", *, step_id: str = "") -> None:
        """åˆå§‹åŒ–è¿›åº¦è¾“å‡ºç»„ä»¶"""
        super().__init__(markdown_content)
        self.step_id = step_id
        self.add_class("progress-line")

    def get_step_id(self) -> str:
        """è·å–æ­¥éª¤ID"""
        return self.step_id


class CommandInput(Input):
    """å‘½ä»¤è¾“å…¥ç»„ä»¶"""

    def __init__(self) -> None:
        """åˆå§‹åŒ–å‘½ä»¤è¾“å…¥ç»„ä»¶"""
        super().__init__(placeholder=_("Enter command or question..."), id="command-input")


class IntelligentTerminal(App):
    """åŸºäº Textual çš„æ™ºèƒ½ç»ˆç«¯åº”ç”¨"""

    CSS_PATH = "css/styles.tcss"

    BINDINGS: ClassVar[list[BindingType]] = [
        Binding(key="ctrl+q", action="request_quit", description=_("Quit")),
        Binding(key="ctrl+s", action="settings", description=_("Settings")),
        Binding(key="ctrl+r", action="reset_conversation", description=_("Reset")),
        Binding(key="ctrl+t", action="choose_agent", description=_("Agent")),
        Binding(key="ctrl+c", action="cancel", description=_("Cancel"), priority=True),
        Binding(key="tab", action="toggle_focus", description=_("Focus")),
    ]

    class SwitchToMCPConfirm(Message):
        """åˆ‡æ¢åˆ° MCP ç¡®è®¤ç•Œé¢çš„æ¶ˆæ¯"""

        def __init__(self, event) -> None:  # noqa: ANN001
            """åˆå§‹åŒ–æ¶ˆæ¯"""
            super().__init__()
            self.event = event

    class SwitchToMCPParameter(Message):
        """åˆ‡æ¢åˆ° MCP å‚æ•°è¾“å…¥ç•Œé¢çš„æ¶ˆæ¯"""

        def __init__(self, event) -> None:  # noqa: ANN001
            """åˆå§‹åŒ–æ¶ˆæ¯"""
            super().__init__()
            self.event = event

    def __init__(self) -> None:
        """åˆå§‹åŒ–åº”ç”¨"""
        super().__init__()
        # è®¾ç½®åº”ç”¨æ ‡é¢˜
        self.title = "openEuler Intelligence"
        self.sub_title = _("Intelligent CLI Assistant {version}").format(version=__version__)
        self.config_manager = ConfigManager()
        self.processing: bool = False
        # æ·»åŠ ä¿å­˜ä»»åŠ¡çš„é›†åˆåˆ°ç±»å±æ€§
        self.background_tasks: set[asyncio.Task] = set()
        # åˆ›å»ºå¹¶ä¿æŒå•ä¸€çš„ LLM å®¢æˆ·ç«¯å®ä¾‹ä»¥ç»´æŒå¯¹è¯å†å²
        self._llm_client: LLMClientBase | None = None
        # å½“å‰é€‰æ‹©çš„æ™ºèƒ½ä½“ - æ ¹æ®é…ç½®çš„ default_app åˆå§‹åŒ–
        self.current_agent: tuple[str, str] = self._get_initial_agent()
        # MCP çŠ¶æ€
        self._mcp_mode: str = "normal"  # "normal", "confirm", "parameter"
        self._current_mcp_task_id: str = ""
        # åˆ›å»ºæ—¥å¿—å®ä¾‹
        self.logger = get_logger(__name__)
        # è¿›åº¦æ¶ˆæ¯è·Ÿè¸ª
        self._current_progress_lines: dict[str, ProgressOutputLine] = {}  # step_id -> ProgressOutputLine

    def compose(self) -> ComposeResult:
        """æ„å»ºç•Œé¢"""
        yield OIHeader()
        yield FocusableContainer(id="output-container")
        with Container(id="input-container", classes="normal-mode"):
            yield CommandInput()
        yield Footer(show_command_palette=False)

    def action_settings(self) -> None:
        """æ‰“å¼€è®¾ç½®é¡µé¢"""
        # åªæœ‰åœ¨ä¸»ç•Œé¢ï¼ˆæ— å…¶ä»–å±å¹•ï¼‰æ—¶æ‰å“åº”
        if not self._is_in_main_interface():
            return
        self.push_screen(SettingsScreen(self.config_manager, self.get_llm_client()))

    def action_request_quit(self) -> None:
        """è¯·æ±‚é€€å‡ºåº”ç”¨"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨é€€å‡ºå¯¹è¯æ¡†
        if self._is_exit_dialog_open():
            return
        self.push_screen(ExitDialog())

    def action_reset_conversation(self) -> None:
        """é‡ç½®å¯¹è¯å†å²è®°å½•çš„åŠ¨ä½œ"""
        # åªæœ‰åœ¨ä¸»ç•Œé¢ï¼ˆæ— å…¶ä»–å±å¹•ï¼‰æ—¶æ‰å“åº”
        if not self._is_in_main_interface():
            return
        if self._llm_client is not None and hasattr(self._llm_client, "reset_conversation"):
            self._llm_client.reset_conversation()
        # æ¸…é™¤å±å¹•ä¸Šçš„æ‰€æœ‰å†…å®¹
        output_container = self.query_one("#output-container")
        output_container.remove_children()
        # æ¸…ç†è¿›åº¦æ¶ˆæ¯è·Ÿè¸ª
        self._current_progress_lines.clear()

    def action_choose_agent(self) -> None:
        """é€‰æ‹©æ™ºèƒ½ä½“çš„åŠ¨ä½œ"""
        # åªæœ‰åœ¨ä¸»ç•Œé¢ï¼ˆæ— å…¶ä»–å±å¹•ï¼‰æ—¶æ‰å“åº”
        if not self._is_in_main_interface():
            return
        # è·å– Hermes å®¢æˆ·ç«¯
        llm_client = self.get_llm_client()

        # æ£€æŸ¥å®¢æˆ·ç«¯ç±»å‹
        if not hasattr(llm_client, "get_available_agents"):
            # æ˜¾ç¤ºåç«¯è¦æ±‚æç¤ºå¯¹è¯æ¡†
            self.push_screen(BackendRequiredDialog())
            return

        # å¼‚æ­¥è·å–æ™ºèƒ½ä½“åˆ—è¡¨
        task = asyncio.create_task(self._show_agent_selection())
        self.background_tasks.add(task)
        task.add_done_callback(self._task_done_callback)

    def action_toggle_focus(self) -> None:
        """åœ¨å‘½ä»¤è¾“å…¥æ¡†å’Œæ–‡æœ¬åŒºåŸŸä¹‹é—´åˆ‡æ¢ç„¦ç‚¹"""
        # è·å–å½“å‰èšç„¦çš„ç»„ä»¶
        focused = self.focused

        # æ£€æŸ¥æ˜¯å¦èšç„¦åœ¨è¾“å…¥ç»„ä»¶ï¼ˆåŒ…æ‹¬ MCP ç»„ä»¶ï¼‰
        is_input_focused = isinstance(focused, CommandInput) or (
            focused is not None and hasattr(focused, "id") and focused.id in ["mcp-confirm", "mcp-parameter"]
        )

        if is_input_focused:
            # å¦‚æœå½“å‰èšç„¦åœ¨è¾“å…¥ç»„ä»¶ï¼Œåˆ™èšç„¦åˆ°è¾“å‡ºå®¹å™¨
            output_container = self.query_one("#output-container", FocusableContainer)
            output_container.focus()
        else:
            # å¦åˆ™èšç„¦åˆ°å½“å‰çš„è¾“å…¥ç»„ä»¶
            self._focus_current_input_widget()

    def action_cancel(self) -> None:
        """å–æ¶ˆå½“å‰æ­£åœ¨è¿›è¡Œçš„æ“ä½œï¼ˆå‘½ä»¤æ‰§è¡Œæˆ–AIé—®ç­”ï¼‰"""
        if self.processing:
            self.logger.info("ç”¨æˆ·è¯·æ±‚å–æ¶ˆå½“å‰æ“ä½œ")

            # å–æ¶ˆå½“å‰æ‰€æœ‰çš„åå°ä»»åŠ¡
            interrupted_count = 0
            for task in list(self.background_tasks):
                if not task.done():
                    task.cancel()
                    interrupted_count += 1
                    self.logger.debug("å·²å–æ¶ˆåå°ä»»åŠ¡")

            # å–æ¶ˆ LLM å®¢æˆ·ç«¯è¯·æ±‚
            if self._llm_client is not None:
                # å¼‚æ­¥è°ƒç”¨å–æ¶ˆæ–¹æ³•
                cancel_task = asyncio.create_task(self._cancel_llm_request())
                self.background_tasks.add(cancel_task)
                cancel_task.add_done_callback(self._task_done_callback)

            if interrupted_count > 0:
                # æ˜¾ç¤ºä¸­æ–­æ¶ˆæ¯
                output_container = self.query_one("#output-container")
                interrupt_line = OutputLine(_("[Cancelled]"))
                output_container.mount(interrupt_line)
                # å¼‚æ­¥æ»šåŠ¨åˆ°åº•éƒ¨
                scroll_task = asyncio.create_task(self._scroll_to_end())
                self.background_tasks.add(scroll_task)
                scroll_task.add_done_callback(self._task_done_callback)
            return

        # å¦‚æœæ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„æ“ä½œï¼Œå°è¯•è°ƒç”¨å½“å‰ç„¦ç‚¹ç»„ä»¶çš„å¤åˆ¶åŠŸèƒ½
        focused_widget = self.focused
        if focused_widget and hasattr(focused_widget, "action_copy"):
            try:
                # æ˜¾å¼è½¬æ¢ä¸º Any ä»¥ç»•è¿‡ç±»å‹æ£€æŸ¥ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ£€æŸ¥äº† hasattr
                cast("Any", focused_widget).action_copy()
            except Exception:
                self.logger.exception("æ‰§è¡Œå¤åˆ¶æ“ä½œå¤±è´¥")
        else:
            self.logger.debug("å½“å‰æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„æ“ä½œå¯ä»¥å–æ¶ˆï¼Œä¸”å½“å‰ç»„ä»¶ä¸æ”¯æŒå¤åˆ¶")

    def on_mount(self) -> None:
        """åˆå§‹åŒ–å®Œæˆæ—¶è®¾ç½®ç„¦ç‚¹å’Œç»‘å®š"""
        # ç¡®ä¿åˆå§‹çŠ¶æ€æ˜¯æ­£å¸¸æ¨¡å¼
        self._mcp_mode = "normal"
        self._current_mcp_task_id = ""

        # æ¸…ç†ä»»ä½•å¯èƒ½çš„é‡å¤ç»„ä»¶
        try:
            # ç§»é™¤ä»»ä½•å¯èƒ½çš„é‡å¤IDç»„ä»¶
            existing_widgets = self.query("#command-input")
            if len(existing_widgets) > 1:
                # å¦‚æœæœ‰å¤šä¸ªç›¸åŒIDçš„ç»„ä»¶ï¼Œç§»é™¤å¤šä½™çš„
                for widget in existing_widgets[1:]:
                    widget.remove()
        except Exception:
            # å¿½ç•¥æ¸…ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸
            self.logger.exception("æ¸…ç†é‡å¤ç»„ä»¶å¤±è´¥")

        self._focus_current_input_widget()

        # åˆå§‹åŒ–é»˜è®¤æ™ºèƒ½ä½“
        self._initialize_default_agent()

    def get_llm_client(self) -> LLMClientBase:
        """è·å–å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œä½¿ç”¨å•ä¾‹æ¨¡å¼ç»´æŒå¯¹è¯å†å²"""
        if self._llm_client is None:
            self._llm_client = BackendFactory.create_client(self.config_manager)

            # åˆå§‹åŒ–æ—¶è®¾ç½®æ™ºèƒ½ä½“çŠ¶æ€
            if (self.current_agent and self.current_agent[0] and
                isinstance(self._llm_client, HermesChatClient)):
                self._llm_client.set_current_agent(self.current_agent[0])

        # ä¸º Hermes å®¢æˆ·ç«¯è®¾ç½® MCP äº‹ä»¶å¤„ç†å™¨ä»¥æ”¯æŒ MCP äº¤äº’
        if isinstance(self._llm_client, HermesChatClient):
            mcp_handler = TUIMCPEventHandler(self, self._llm_client)
            self._llm_client.set_mcp_handler(mcp_handler)

            # ç¡®ä¿æ™ºèƒ½ä½“çŠ¶æ€åŒæ­¥
            if self.current_agent and self.current_agent[0]:
                current_client_agent = getattr(self._llm_client, "current_agent_id", "")
                if current_client_agent != self.current_agent[0]:
                    self._llm_client.set_current_agent(self.current_agent[0])

        return self._llm_client

    def refresh_llm_client(self) -> None:
        """åˆ·æ–° LLM å®¢æˆ·ç«¯å®ä¾‹ï¼Œç”¨äºé…ç½®æ›´æ”¹åé‡æ–°åˆ›å»ºå®¢æˆ·ç«¯"""
        # ä¿å­˜å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
        current_agent_id = self.current_agent[0] if self.current_agent else ""

        self._llm_client = BackendFactory.create_client(self.config_manager)

        # æ¢å¤æ™ºèƒ½ä½“çŠ¶æ€åˆ°æ–°çš„å®¢æˆ·ç«¯
        if current_agent_id and isinstance(self._llm_client, HermesChatClient):
            self._llm_client.set_current_agent(current_agent_id)

        # ä¸º Hermes å®¢æˆ·ç«¯è®¾ç½® MCP äº‹ä»¶å¤„ç†å™¨
        if isinstance(self._llm_client, HermesChatClient):
            mcp_handler = TUIMCPEventHandler(self, self._llm_client)
            self._llm_client.set_mcp_handler(mcp_handler)

        # åç«¯åˆ‡æ¢æ—¶é‡æ–°åˆå§‹åŒ–æ™ºèƒ½ä½“çŠ¶æ€
        self._reinitialize_agent_state()

    def exit(self, *args, **kwargs) -> None:  # noqa: ANN002, ANN003
        """é€€å‡ºåº”ç”¨å‰å–æ¶ˆæ‰€æœ‰åå°ä»»åŠ¡"""
        # å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿è¡Œçš„åå°ä»»åŠ¡
        for task in self.background_tasks:
            if not task.done():
                task.cancel()

        # æ¸…ç† LLM å®¢æˆ·ç«¯è¿æ¥
        if self._llm_client is not None:
            # åˆ›å»ºæ¸…ç†ä»»åŠ¡å¹¶åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ
            cleanup_task = asyncio.create_task(self._cleanup_llm_client())
            self.background_tasks.add(cleanup_task)
            cleanup_task.add_done_callback(self._cleanup_task_done_callback)

        # è°ƒç”¨çˆ¶ç±»çš„exitæ–¹æ³•
        super().exit(*args, **kwargs)

    @on(Input.Submitted, "#command-input")
    def handle_input(self, event: Input.Submitted) -> None:
        """å¤„ç†å‘½ä»¤è¾“å…¥"""
        if not self._is_in_main_interface():
            return

        user_input = event.value.strip()
        if not user_input or self.processing:
            return

        # æ¸…ç©ºè¾“å…¥æ¡†
        input_widget = self.query_one(CommandInput)
        input_widget.value = ""

        # æ˜¾ç¤ºå‘½ä»¤
        output_container = self.query_one("#output-container")
        output_container.mount(OutputLine(f"> {user_input}", command=True))

        # æ»šåŠ¨åˆ°è¾“å‡ºå®¹å™¨çš„åº•éƒ¨
        output_container.scroll_end(animate=False)

        # å¼‚æ­¥å¤„ç†å‘½ä»¤
        self.processing = True
        # åˆ›å»ºä»»åŠ¡å¹¶ä¿å­˜åˆ°ç±»å±æ€§ä¸­çš„ä»»åŠ¡é›†åˆ
        task = asyncio.create_task(self._process_command(user_input))
        self.background_tasks.add(task)
        # æ·»åŠ å®Œæˆå›è°ƒï¼Œè‡ªåŠ¨ä»é›†åˆä¸­ç§»é™¤
        task.add_done_callback(self._task_done_callback)

    @on(SwitchToMCPConfirm)
    def handle_switch_to_mcp_confirm(self, message: SwitchToMCPConfirm) -> None:
        """å¤„ç†åˆ‡æ¢åˆ° MCP ç¡®è®¤ç•Œé¢çš„æ¶ˆæ¯"""
        self._mcp_mode = "confirm"
        self._current_mcp_task_id = message.event.get_task_id()
        self._replace_input_with_mcp_widget(MCPConfirmWidget(message.event, widget_id="mcp-confirm"))

    @on(SwitchToMCPParameter)
    def handle_switch_to_mcp_parameter(self, message: SwitchToMCPParameter) -> None:
        """å¤„ç†åˆ‡æ¢åˆ° MCP å‚æ•°è¾“å…¥ç•Œé¢çš„æ¶ˆæ¯"""
        self._mcp_mode = "parameter"
        self._current_mcp_task_id = message.event.get_task_id()
        self._replace_input_with_mcp_widget(MCPParameterWidget(message.event, widget_id="mcp-parameter"))

    @on(MCPConfirmResult)
    def handle_mcp_confirm_result(self, message: MCPConfirmResult) -> None:
        """å¤„ç† MCP ç¡®è®¤ç»“æœ"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯å½“å‰ä»»åŠ¡ä¸”æœªåœ¨å¤„ç†ä¸­
        if message.task_id == self._current_mcp_task_id and not self.processing:
            self.processing = True  # è®¾ç½®å¤„ç†æ ‡å¿—ï¼Œé˜²æ­¢é‡å¤å¤„ç†
            # ç«‹å³æ¢å¤æ­£å¸¸è¾“å…¥ç•Œé¢
            self._restore_normal_input()
            # å‘é€ MCP å“åº”å¹¶å¤„ç†ç»“æœ
            task = asyncio.create_task(self._send_mcp_response(message.task_id, params=message.confirmed))
            self.background_tasks.add(task)
            task.add_done_callback(self._task_done_callback)

    @on(MCPParameterResult)
    def handle_mcp_parameter_result(self, message: MCPParameterResult) -> None:
        """å¤„ç† MCP å‚æ•°ç»“æœ"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯å½“å‰ä»»åŠ¡ä¸”æœªåœ¨å¤„ç†ä¸­
        if message.task_id == self._current_mcp_task_id and not self.processing:
            self.processing = True  # è®¾ç½®å¤„ç†æ ‡å¿—ï¼Œé˜²æ­¢é‡å¤å¤„ç†
            # ç«‹å³æ¢å¤æ­£å¸¸è¾“å…¥ç•Œé¢
            self._restore_normal_input()
            # å‘é€ MCP å“åº”å¹¶å¤„ç†ç»“æœ
            params = message.params if message.params is not None else False
            task = asyncio.create_task(self._send_mcp_response(message.task_id, params=params))
            self.background_tasks.add(task)
            task.add_done_callback(self._task_done_callback)

    def _is_in_main_interface(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨ä¸»ç•Œé¢ï¼ˆæ²¡æœ‰å…¶ä»–å±å¹•å¼¹å‡ºï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰æ´»åŠ¨çš„å±å¹•æ ˆï¼Œé™¤äº†ä¸»å±å¹•å¤–æ²¡æœ‰å…¶ä»–å±å¹•
        return len(self.screen_stack) <= 1

    def _is_exit_dialog_open(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²ç»æ‰“å¼€äº†é€€å‡ºå¯¹è¯æ¡†"""
        # æ£€æŸ¥å½“å‰æ´»åŠ¨å±å¹•æ˜¯å¦æ˜¯é€€å‡ºå¯¹è¯æ¡†
        current_screen = self.screen
        return hasattr(current_screen, "__class__") and current_screen.__class__.__name__ == "ExitDialog"

    def _task_done_callback(self, task: asyncio.Task) -> None:
        """ä»»åŠ¡å®Œæˆå›è°ƒï¼Œä»ä»»åŠ¡é›†åˆä¸­ç§»é™¤"""
        if task in self.background_tasks:
            self.background_tasks.remove(task)
        # æ•è·ä»»åŠ¡ä¸­çš„å¼‚å¸¸ï¼Œé˜²æ­¢æœªå¤„ç†å¼‚å¸¸
        try:
            task.result()
        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆæ˜¯æ­£å¸¸æƒ…å†µï¼Œä¸éœ€è¦è®°å½•é”™è¯¯
            pass
        except Exception as e:
            # è®°å½•é”™è¯¯æ—¥å¿—
            self.logger.exception("Task execution error occurred")
            # å°è¯•åœ¨å‰ç«¯æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            self._display_error_in_ui(e)
        finally:
            # ç¡®ä¿å¤„ç†æ ‡å¿—è¢«é‡ç½®
            self.processing = False

    async def _cancel_llm_request(self) -> None:
        """å¼‚æ­¥å–æ¶ˆ LLM è¯·æ±‚"""
        try:
            if self._llm_client is not None:
                await self._llm_client.interrupt()
                self.logger.info("LLM è¯·æ±‚å·²å–æ¶ˆ")
        except Exception:
            self.logger.exception("å–æ¶ˆ LLM è¯·æ±‚æ—¶å‡ºé”™")

    async def _process_command(self, user_input: str) -> None:
        """å¼‚æ­¥å¤„ç†å‘½ä»¤"""
        try:
            output_container = self.query_one("#output-container", Container)
            received_any_content = await self._handle_command_stream(user_input, output_container)

            # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•å†…å®¹ä¸”åº”ç”¨ä»åœ¨è¿è¡Œï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if not received_any_content and hasattr(self, "is_running") and self.is_running:
                output_container.mount(
                    OutputLine(
                        _("No response received, please check network connection or try again later"),
                        command=False,
                    ),
                )

        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆï¼Œé€šå¸¸æ˜¯å› ä¸ºåº”ç”¨é€€å‡º
            self.logger.info("Command processing cancelled")
        except Exception as e:
            # è®°å½•é”™è¯¯æ—¥å¿—
            self.logger.exception("Command processing error occurred")
            # æ·»åŠ å¼‚å¸¸å¤„ç†ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            try:
                output_container = self.query_one("#output-container", Container)
                error_msg = self._format_error_message(e)
                # æ£€æŸ¥åº”ç”¨æ˜¯å¦å·²ç»å¼€å§‹é€€å‡º
                if hasattr(self, "is_running") and self.is_running:
                    output_container.mount(OutputLine(format_error_message(error_msg), command=False))
            except (AttributeError, ValueError, RuntimeError):
                # å¦‚æœUIç»„ä»¶å·²ä¸å¯ç”¨ï¼Œåªè®°å½•é”™è¯¯æ—¥å¿—
                self.logger.exception("Failed to display error message")
        finally:
            # é‡æ–°èšç„¦åˆ°è¾“å…¥æ¡†ï¼ˆå¦‚æœåº”ç”¨ä»åœ¨è¿è¡Œï¼‰
            try:
                if hasattr(self, "is_running") and self.is_running:
                    self._focus_current_input_widget()
            except (AttributeError, ValueError, RuntimeError):
                # åº”ç”¨å¯èƒ½æ­£åœ¨é€€å‡ºï¼Œå¿½ç•¥èšç„¦é”™è¯¯
                self.logger.debug("[TUI] Failed to focus input widget, app may be exiting")
            # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œé‡ç½®processingæ ‡å¿—ï¼Œç”±å›è°ƒå‡½æ•°å¤„ç†

    async def _handle_command_stream(self, user_input: str, output_container: Container) -> bool:
        """å¤„ç†å‘½ä»¤æµå¼å“åº”"""
        # åœ¨æ–°çš„å‘½ä»¤ä¼šè¯å¼€å§‹æ—¶é‡ç½®MCPçŠ¶æ€è·Ÿè¸ª
        if self._llm_client and isinstance(self._llm_client, HermesChatClient):
            self._llm_client.stream_processor.reset_status_tracking()

        stream_state = self._init_stream_state()

        try:
            received_any_content = await self._process_stream(
                user_input,
                output_container,
                stream_state,
            )
        except TimeoutError:
            received_any_content = self._handle_timeout_error(output_container, stream_state)
        except asyncio.CancelledError:
            received_any_content = self._handle_cancelled_error(output_container, stream_state)

        return received_any_content

    def _init_stream_state(self) -> dict:
        """åˆå§‹åŒ–æµå¤„ç†çŠ¶æ€"""
        start_time = asyncio.get_event_loop().time()
        return {
            "current_line": None,
            "current_content": "",
            "is_first_content": True,
            "received_any_content": False,
            "start_time": start_time,
            "timeout_seconds": None,  # æ— æ€»ä½“è¶…æ—¶é™åˆ¶ï¼Œæ”¯æŒè¶…é•¿æ—¶é—´ä»»åŠ¡
            "last_content_time": start_time,
            "no_content_timeout": 1800.0,  # 30åˆ†é’Ÿæ— å†…å®¹è¶…æ—¶
        }

    async def _process_stream(
        self,
        user_input: str,
        output_container: Container,
        stream_state: dict,
    ) -> bool:
        """å¤„ç†å‘½ä»¤è¾“å‡ºæµ"""
        async for output_tuple in process_command(user_input, self.get_llm_client()):
            content, is_llm_output = output_tuple
            stream_state["received_any_content"] = True
            current_time = asyncio.get_event_loop().time()

            # æ›´æ–°æœ€åæ”¶åˆ°å†…å®¹çš„æ—¶é—´
            if content.strip():
                stream_state["last_content_time"] = current_time

            # æ£€æŸ¥è¶…æ—¶
            if self._check_timeouts(current_time, stream_state, output_container):
                break

            # å¤„ç†å†…å®¹
            await self._process_stream_content(
                content,
                stream_state,
                output_container,
                is_llm_output=is_llm_output,
            )

            # æ»šåŠ¨åˆ°åº•éƒ¨
            await self._scroll_to_end()

        return stream_state["received_any_content"]

    def _check_timeouts(
        self,
        current_time: float,
        stream_state: dict,
        output_container: Container,
    ) -> bool:
        """æ£€æŸ¥å„ç§è¶…æ—¶æ¡ä»¶ï¼Œè¿”å›æ˜¯å¦åº”è¯¥ä¸­æ–­å¤„ç†"""
        timeout_seconds = stream_state["timeout_seconds"]
        if timeout_seconds is not None and current_time - stream_state["start_time"] > timeout_seconds:
            output_container.mount(OutputLine(_("Request timeout, processing stopped"), command=False))
            return True

        # æ£€æŸ¥æ— å†…å®¹è¶…æ—¶
        received_any_content = stream_state["received_any_content"]
        time_since_last_content = current_time - stream_state["last_content_time"]
        if received_any_content and time_since_last_content > stream_state["no_content_timeout"]:
            output_container.mount(OutputLine(_("No response for a long time, processing stopped"), command=False))
            return True

        return False

    async def _process_stream_content(
        self,
        content: str,
        stream_state: dict,
        output_container: Container,
        *,
        is_llm_output: bool,
    ) -> None:
        """å¤„ç†æµå¼å†…å®¹"""
        params = ContentChunkParams(
            content=content,
            is_llm_output=is_llm_output,
            current_content=stream_state["current_content"],
            is_first_content=stream_state["is_first_content"],
        )

        processed_line = await self._process_content_chunk(
            params,
            stream_state["current_line"],
            output_container,
        )

        # æ£€æŸ¥æ˜¯å¦æ˜¯ MCP æ¶ˆæ¯å¤„ç†ï¼ˆè¿”å›å€¼ä¸º None è¡¨ç¤ºæ˜¯ MCP æ¶ˆæ¯ï¼‰
        tool_name, _cleaned_content = extract_mcp_tag(content)
        is_mcp_detected = processed_line is None and tool_name is not None

        # åªæœ‰å½“è¿”å›å€¼ä¸ä¸ºNoneæ—¶æ‰æ›´æ–°current_line
        if processed_line is not None:
            stream_state["current_line"] = processed_line

        # æ›´æ–°çŠ¶æ€ - ä½†æ˜¯ä¸è¦è®© MCP æ¶ˆæ¯å½±å“æµçŠ¶æ€
        if not is_mcp_detected:
            if stream_state["is_first_content"]:
                stream_state["is_first_content"] = False
                # ç¬¬ä¸€æ¬¡å†…å®¹ç›´æ¥è®¾ç½®ä¸ºå½“å‰å†…å®¹ï¼Œä¸éœ€è¦ç´¯ç§¯
                if is_llm_output:
                    stream_state["current_content"] = content
                else:
                    # éLLMè¾“å‡ºï¼Œé‡ç½®ç´¯ç§¯å†…å®¹
                    stream_state["current_content"] = ""
            elif isinstance(stream_state["current_line"], MarkdownOutput) and is_llm_output:
                # åªæœ‰åœ¨LLMè¾“å‡ºä¸”æœ‰æœ‰æ•ˆçš„ MarkdownOutput æ—¶æ‰ç´¯ç§¯
                stream_state["current_content"] += content

    def _handle_timeout_error(self, output_container: Container, stream_state: dict) -> bool:
        """å¤„ç†è¶…æ—¶é”™è¯¯"""
        self.logger.warning("Command stream timed out")
        if hasattr(self, "is_running") and self.is_running:
            output_container.mount(OutputLine(_("Request timeout, please try again later"), command=False))
        return stream_state["received_any_content"]

    def _handle_cancelled_error(self, output_container: Container, stream_state: dict) -> bool:
        """å¤„ç†å–æ¶ˆé”™è¯¯"""
        self.logger.info("Command stream was cancelled")
        return stream_state["received_any_content"]

    async def _process_content_chunk(
        self,
        params: ContentChunkParams,
        current_line: OutputLine | MarkdownOutput | None,
        output_container: Container,
    ) -> OutputLine | MarkdownOutput | None:
        """å¤„ç†å•ä¸ªå†…å®¹å—"""
        content = params.content
        is_llm_output = params.is_llm_output
        current_content = params.current_content
        is_first_content = params.is_first_content

        # æ£€æŸ¥æ˜¯å¦åŒ…å«MCPæ ‡è®°ï¼ˆæ›¿æ¢æ ‡è®°æˆ–MCPæ ‡è®°ï¼‰
        tool_name, cleaned_content = extract_mcp_tag(content)
        replace_tool_name = None
        mcp_tool_name = None

        # æ ¹æ®åŸå§‹å†…å®¹åˆ¤æ–­æ ‡è®°ç±»å‹
        if tool_name:
            if MCPTags.REPLACE_PREFIX in content:
                replace_tool_name = tool_name
            elif MCPTags.MCP_PREFIX in content:
                mcp_tool_name = tool_name

        # æ£€æŸ¥æ˜¯å¦ä¸º MCP è¿›åº¦æ¶ˆæ¯
        tool_name = replace_tool_name or mcp_tool_name
        is_progress_message = tool_name is not None and is_mcp_message(content)

        # å¦‚æœæ˜¯è¿›åº¦æ¶ˆæ¯ï¼Œä½¿ç”¨ä¸“é—¨çš„å¤„ç†æ–¹æ³•ï¼Œæ— è®º is_llm_output çš„å€¼
        if is_progress_message and tool_name:
            return self._handle_mcp_progress_message(
                cleaned_content,
                tool_name,
                replace_tool_name,
                mcp_tool_name,
                output_container,
            )

        # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹è¿›è¡Œåç»­å¤„ç†
        content = cleaned_content

        self.logger.debug("[TUI] å¤„ç†å†…å®¹: %s", content.strip()[:50])

        # å¤„ç†ç¬¬ä¸€æ®µå†…å®¹ï¼Œåˆ›å»ºé€‚å½“çš„è¾“å‡ºç»„ä»¶
        if is_first_content:
            new_line: OutputLine | MarkdownOutput = (
                MarkdownOutput(content) if is_llm_output else OutputLine(content)
            )
            output_container.mount(new_line)
            return new_line

        # å¤„ç†åç»­å†…å®¹
        if is_llm_output and isinstance(current_line, MarkdownOutput):
            # ç»§ç»­ç´¯ç§¯LLMå¯Œæ–‡æœ¬å†…å®¹
            # æ³¨æ„ï¼šcurrent_content å·²ç»åŒ…å«äº†ä¹‹å‰çš„æ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬ç¬¬ä¸€æ¬¡çš„å†…å®¹
            updated_content = current_content + content
            current_line.update_markdown(updated_content)
            return current_line

        if not is_llm_output and isinstance(current_line, OutputLine):
            # ç»§ç»­ç´¯ç§¯å‘½ä»¤è¾“å‡ºçº¯æ–‡æœ¬
            current_text = current_line.get_content()
            current_line.update(current_text + content)
            return current_line

        # è¾“å‡ºç±»å‹å‘ç”Ÿå˜åŒ–ï¼Œåˆ›å»ºæ–°çš„è¾“å‡ºç»„ä»¶
        # å¯¹äºè¾“å‡ºç±»å‹å˜åŒ–ï¼Œå¦‚æœæ˜¯LLMè¾“å‡ºï¼Œåº”è¯¥åŒ…å«ç´¯ç§¯çš„å†…å®¹ï¼›å¦åˆ™åªåŒ…å«å½“å‰å†…å®¹
        if is_llm_output:
            # å¦‚æœåˆ‡æ¢åˆ°LLMè¾“å‡ºï¼Œä½¿ç”¨ç´¯ç§¯çš„å†…å®¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            content_to_display = current_content + content if current_content else content
            new_line = MarkdownOutput(content_to_display)
        else:
            # å¦‚æœåˆ‡æ¢åˆ°éLLMè¾“å‡ºï¼Œåªä½¿ç”¨å½“å‰å†…å®¹
            new_line = OutputLine(content)
        output_container.mount(new_line)
        return new_line

    def _handle_mcp_progress_message(
        self,
        content: str,
        tool_name: str,
        replace_tool_name: str | None,
        mcp_tool_name: str | None,
        output_container: Container,
    ) -> None:
        """å¤„ç† MCP è¿›åº¦æ¶ˆæ¯"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ç»ˆçŠ¶æ€æ¶ˆæ¯
        is_final_message = is_final_mcp_message(content)

        # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰çš„è¿›åº¦æ¶ˆæ¯
        existing_progress = self._current_progress_lines.get(tool_name)

        # å¦‚æœæœ‰æ›¿æ¢æ ‡è®°ï¼Œåˆ™å°è¯•æ›¿æ¢ç°æœ‰æ¶ˆæ¯
        if replace_tool_name and existing_progress is not None:
            # æ›¿æ¢ç°æœ‰çš„è¿›åº¦æ¶ˆæ¯
            existing_progress.update_markdown(content)
            self.logger.debug("[TUI] æ›¿æ¢å·¥å…· %s çš„è¿›åº¦æ¶ˆæ¯: %s", tool_name, content.strip()[:50])

            # å¦‚æœæ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œæ¸…ç†è¿›åº¦è·Ÿè¸ª
            if is_final_message:
                self._current_progress_lines.pop(tool_name, None)
                self.logger.debug("[TUI] å·¥å…· %s åˆ°è¾¾æœ€ç»ˆçŠ¶æ€ï¼Œæ¸…ç†è¿›åº¦è·Ÿè¸ª", tool_name)

            return

        # å¦‚æœæœ‰MCPæ ‡è®°ä½†å·²å­˜åœ¨ç›¸åŒå·¥å…·çš„è¿›åº¦æ¶ˆæ¯ï¼Œåˆ™æ›¿æ¢è€Œä¸æ˜¯åˆ›å»ºæ–°çš„
        if mcp_tool_name and existing_progress is not None:
            # è¿™ç§æƒ…å†µå¯èƒ½æ˜¯å› ä¸ºæ¶ˆæ¯å¤„ç†é¡ºåºé—®é¢˜å¯¼è‡´çš„é‡å¤ï¼Œåº”è¯¥æ›¿æ¢ç°æœ‰æ¶ˆæ¯
            existing_progress.update_markdown(content)
            self.logger.debug("[TUI] æ›¿æ¢å·²å­˜åœ¨çš„å·¥å…· %s è¿›åº¦æ¶ˆæ¯: %s", tool_name, content.strip()[:50])

            # å¦‚æœæ˜¯æœ€ç»ˆçŠ¶æ€ï¼Œæ¸…ç†è¿›åº¦è·Ÿè¸ª
            if is_final_message:
                self._current_progress_lines.pop(tool_name, None)
                self.logger.debug("[TUI] å·¥å…· %s åˆ°è¾¾æœ€ç»ˆçŠ¶æ€ï¼Œæ¸…ç†è¿›åº¦è·Ÿè¸ª", tool_name)

            return

        # åˆ›å»ºæ–°çš„è¿›åº¦æ¶ˆæ¯
        new_progress_line = ProgressOutputLine(content, step_id=tool_name)

        # å¦‚æœä¸æ˜¯æœ€ç»ˆçŠ¶æ€ï¼ŒåŠ å…¥è¿›åº¦è·Ÿè¸ª
        if not is_final_message:
            self._current_progress_lines[tool_name] = new_progress_line

        output_container.mount(new_progress_line)
        self.logger.debug("[TUI] åˆ›å»ºå·¥å…· %s çš„æ–°è¿›åº¦æ¶ˆæ¯: %s", tool_name, content.strip()[:50])

    def _format_error_message(self, error: BaseException) -> str:
        """æ ¼å¼åŒ–é”™è¯¯æ¶ˆæ¯"""
        error_str = str(error).lower()
        error_type = type(error).__name__.lower()

        # å¤„ç† HermesAPIError ç‰¹æ®Šæƒ…å†µ
        if hasattr(error, "status_code") and hasattr(error, "message"):
            if error.status_code == 500:  # type: ignore[attr-defined]  # noqa: PLR2004
                return _("Server error: {message}").format(message=error.message)  # type: ignore[attr-defined]
            if error.status_code >= 400:  # type: ignore[attr-defined]  # noqa: PLR2004
                return _("Request failed: {message}").format(message=error.message)  # type: ignore[attr-defined]

        # å®šä¹‰é”™è¯¯åŒ¹é…è§„åˆ™å’Œå¯¹åº”çš„ç”¨æˆ·å‹å¥½æ¶ˆæ¯
        error_patterns = {
            _("Network connection interrupted, please check network and try again"): [
                "remoteprotocolerror",
                "server disconnected",
                "peer closed connection",
                "connection reset",
                "connection refused",
                "broken pipe",
            ],
            _("Request timeout, please try again later"): [
                "timeout",
                "timed out",
            ],
            _("Network connection error, please check network and try again"): [
                "network",
                "connection",
                "unreachable",
                "resolve",
                "dns",
                "httperror",
                "requestserror",
            ],
            _("Server response error, please try again later"): [
                "http",
                "status",
                "response",
            ],
            _("Data format error, please try again later"): [
                "json",
                "decode",
                "parse",
                "invalid",
                "malformed",
            ],
            _("Authentication failed, please check configuration"): [
                "auth",
                "unauthorized",
                "forbidden",
                "token",
            ],
        }

        # æ£€æŸ¥é”™è¯¯å­—ç¬¦ä¸²åŒ¹é…
        for message, patterns in error_patterns.items():
            if any(pattern in error_str for pattern in patterns):
                return message

        # æ£€æŸ¥é”™è¯¯ç±»å‹åŒ¹é…ï¼ˆç”¨äºæœåŠ¡ç«¯å“åº”å¼‚å¸¸ï¼‰
        if any(
            keyword in error_type
            for keyword in [
                "httperror",
                "httpstatuserror",
                "requesterror",
            ]
        ):
            return _("Server response error, please try again later")

        return _("Error processing command: {error}").format(error=str(error))

    def _display_error_in_ui(self, error: BaseException) -> None:
        """åœ¨UIç•Œé¢æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯"""
        try:
            # æ£€æŸ¥åº”ç”¨æ˜¯å¦ä»åœ¨è¿è¡Œ
            if not (hasattr(self, "is_running") and self.is_running):
                return

            # è·å–è¾“å‡ºå®¹å™¨
            output_container = self.query_one("#output-container", Container)

            # æ ¼å¼åŒ–é”™è¯¯æ¶ˆæ¯
            error_msg = self._format_error_message(error)

            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            output_container.mount(OutputLine(f"âŒ {error_msg}", command=False))

            # æ»šåŠ¨åˆ°åº•éƒ¨ä»¥ç¡®ä¿ç”¨æˆ·çœ‹åˆ°é”™è¯¯ä¿¡æ¯
            self.call_after_refresh(lambda: output_container.scroll_end(animate=False))

        except Exception:
            # å¦‚æœUIæ˜¾ç¤ºå¤±è´¥ï¼Œè‡³å°‘è®°å½•é”™è¯¯æ—¥å¿—
            self.logger.exception("æ— æ³•åœ¨UIä¸­æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯")

    def _focus_current_input_widget(self) -> None:
        """èšç„¦åˆ°å½“å‰çš„è¾“å…¥ç»„ä»¶ï¼Œè€ƒè™‘ MCP æ¨¡å¼çŠ¶æ€"""
        try:
            if self._mcp_mode == "normal":
                # æ­£å¸¸æ¨¡å¼ï¼Œèšç„¦åˆ° CommandInput
                self.query_one(CommandInput).focus()
            elif self._mcp_mode == "confirm":
                # MCP ç¡®è®¤æ¨¡å¼ï¼Œèšç„¦åˆ° MCP ç¡®è®¤ç»„ä»¶
                try:
                    mcp_widget = self.query_one("#mcp-confirm")
                    mcp_widget.focus()
                except (AttributeError, ValueError, RuntimeError):
                    # å¦‚æœMCPç»„ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°æ­£å¸¸æ¨¡å¼
                    self._mcp_mode = "normal"
                    self.query_one(CommandInput).focus()
            elif self._mcp_mode == "parameter":
                # MCP å‚æ•°æ¨¡å¼ï¼Œèšç„¦åˆ° MCP å‚æ•°ç»„ä»¶
                try:
                    mcp_widget = self.query_one("#mcp-parameter")
                    mcp_widget.focus()
                except (AttributeError, ValueError, RuntimeError):
                    # å¦‚æœMCPç»„ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°æ­£å¸¸æ¨¡å¼
                    self._mcp_mode = "normal"
                    self.query_one(CommandInput).focus()
            else:
                # æœªçŸ¥æ¨¡å¼ï¼Œé‡ç½®ä¸ºæ­£å¸¸æ¨¡å¼å¹¶èšç„¦åˆ° CommandInput
                self.logger.warning("æœªçŸ¥çš„ MCP æ¨¡å¼: %sï¼Œé‡ç½®ä¸ºæ­£å¸¸æ¨¡å¼", self._mcp_mode)
                self._mcp_mode = "normal"
                self.query_one(CommandInput).focus()
        except (AttributeError, ValueError, RuntimeError) as e:
            # èšç„¦å¤±è´¥æ—¶è®°å½•è°ƒè¯•ä¿¡æ¯ï¼Œä½†ä¸æŠ›å‡ºå¼‚å¸¸
            self.logger.debug("[TUI] Failed to focus input widget: %s", str(e))

    async def _scroll_to_end(self) -> None:
        """æ»šåŠ¨åˆ°å®¹å™¨åº•éƒ¨çš„è¾…åŠ©æ–¹æ³•"""
        # è·å–è¾“å‡ºå®¹å™¨
        output_container = self.query_one("#output-container")
        # ä½¿ç”¨åŒæ­¥æ–¹æ³•æ»šåŠ¨ï¼Œç¡®ä¿UIæ›´æ–°
        output_container.scroll_end(animate=False)
        # ç­‰å¾…ä¸€ä¸ªå°çš„å»¶è¿Ÿï¼Œç¡®ä¿UIæœ‰æ—¶é—´æ›´æ–°
        await asyncio.sleep(0.01)

    async def _cleanup_llm_client(self) -> None:
        """å¼‚æ­¥æ¸…ç† LLM å®¢æˆ·ç«¯"""
        if self._llm_client is not None:
            try:
                await self._llm_client.close()
                self.logger.info("LLM å®¢æˆ·ç«¯å·²å®‰å…¨å…³é—­")
            except (OSError, RuntimeError, ValueError) as e:
                log_exception(self.logger, "å…³é—­ LLM å®¢æˆ·ç«¯æ—¶å‡ºé”™", e)

    def _cleanup_task_done_callback(self, task: asyncio.Task) -> None:
        """æ¸…ç†ä»»åŠ¡å®Œæˆå›è°ƒ"""
        if task in self.background_tasks:
            self.background_tasks.remove(task)
        try:
            task.result()
        except asyncio.CancelledError:
            pass
        except (OSError, ValueError, RuntimeError):
            self.logger.exception("LLM client cleanup error")

    async def _show_agent_selection(self) -> None:
        """æ˜¾ç¤ºæ™ºèƒ½ä½“é€‰æ‹©å¯¹è¯æ¡†"""
        try:
            llm_client = self.get_llm_client()

            # æ„å»ºæ™ºèƒ½ä½“åˆ—è¡¨ - é»˜è®¤ç¬¬ä¸€é¡¹ä¸º"æ™ºèƒ½é—®ç­”"ï¼ˆæ— æ™ºèƒ½ä½“ï¼‰
            agent_list = [("", _("æ™ºèƒ½é—®ç­”"))]

            # å°è¯•è·å–å¯ç”¨æ™ºèƒ½ä½“
            if hasattr(llm_client, "get_available_agents"):
                try:
                    available_agents = await llm_client.get_available_agents()  # type: ignore[attr-defined]
                    # æ·»åŠ è·å–åˆ°çš„æ™ºèƒ½ä½“
                    agent_list.extend(
                        [
                            (agent.app_id, agent.name)
                            for agent in available_agents
                            if hasattr(agent, "app_id") and hasattr(agent, "name")
                        ],
                    )
                except (AttributeError, OSError, ValueError, RuntimeError) as e:
                    self.logger.warning("è·å–æ™ºèƒ½ä½“åˆ—è¡¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹: %s", str(e))
                    # ç»§ç»­ä½¿ç”¨é»˜è®¤çš„æ™ºèƒ½é—®ç­”é€‰é¡¹
            else:
                self.logger.info("å½“å‰å®¢æˆ·ç«¯ä¸æ”¯æŒæ™ºèƒ½ä½“åŠŸèƒ½ï¼Œæ˜¾ç¤ºé»˜è®¤é€‰é¡¹")

            # ä½¿ç”¨å½“å‰æ™ºèƒ½ä½“çŠ¶æ€ï¼Œä¸é‡æ–°è¯»å–é…ç½®
            await self._display_agent_dialog(agent_list, llm_client)

        except (OSError, ValueError, RuntimeError) as e:
            log_exception(self.logger, "æ˜¾ç¤ºæ™ºèƒ½ä½“é€‰æ‹©å¯¹è¯æ¡†å¤±è´¥", e)
            # å³ä½¿å‡ºé”™ä¹Ÿæ˜¾ç¤ºé»˜è®¤é€‰é¡¹
            agent_list = [("", _("æ™ºèƒ½é—®ç­”"))]
            try:
                llm_client = self.get_llm_client()
                await self._display_agent_dialog(agent_list, llm_client)
            except (OSError, ValueError, RuntimeError, AttributeError):
                self.logger.exception("æ— æ³•æ˜¾ç¤ºæ™ºèƒ½ä½“é€‰æ‹©å¯¹è¯æ¡†")

    async def _display_agent_dialog(
        self,
        agent_list: list[tuple[str, str]],
        llm_client: LLMClientBase,
    ) -> None:
        """æ˜¾ç¤ºæ™ºèƒ½ä½“é€‰æ‹©å¯¹è¯æ¡†"""

        def on_agent_selected(selected_agent: tuple[str, str]) -> None:
            """æ™ºèƒ½ä½“é€‰æ‹©å›è°ƒ"""
            self.current_agent = selected_agent
            app_id, _name = selected_agent

            # è®¾ç½®æ™ºèƒ½ä½“åˆ°å®¢æˆ·ç«¯
            if isinstance(llm_client, HermesChatClient):
                llm_client.set_current_agent(app_id)

        dialog = AgentSelectionDialog(agent_list, on_agent_selected, self.current_agent)
        self.push_screen(dialog)

    def _replace_input_with_mcp_widget(self, widget) -> None:  # noqa: ANN001
        """æ›¿æ¢è¾“å…¥å®¹å™¨ä¸­çš„ç»„ä»¶ä¸º MCP äº¤äº’ç»„ä»¶"""
        try:
            input_container = self.query_one("#input-container")

            # åˆ‡æ¢åˆ° MCP æ¨¡å¼æ ·å¼
            input_container.remove_class("normal-mode")
            input_container.add_class("mcp-mode")

            # ç§»é™¤æ‰€æœ‰å­ç»„ä»¶
            input_container.remove_children()

            # æ·»åŠ æ–°çš„ MCP ç»„ä»¶
            input_container.mount(widget)

            # å»¶è¿Ÿèšç„¦ï¼Œç¡®ä¿ç»„ä»¶å®Œå…¨æŒ‚è½½
            self.set_timer(0.05, lambda: widget.focus())

        except Exception:
            self.logger.exception("æ›¿æ¢è¾“å…¥ç»„ä»¶å¤±è´¥")
            # å¦‚æœæ›¿æ¢å¤±è´¥ï¼Œå°è¯•æ¢å¤æ­£å¸¸è¾“å…¥
            try:
                self._restore_normal_input()
            except Exception:
                self.logger.exception("æ¢å¤æ­£å¸¸è¾“å…¥å¤±è´¥")

    def _restore_normal_input(self) -> None:
        """æ¢å¤æ­£å¸¸çš„å‘½ä»¤è¾“å…¥ç»„ä»¶"""
        try:
            input_container = self.query_one("#input-container")

            # é‡ç½® MCP çŠ¶æ€
            self._mcp_mode = "normal"
            self._current_mcp_task_id = ""

            # åˆ‡æ¢å›æ­£å¸¸æ¨¡å¼æ ·å¼
            input_container.remove_class("mcp-mode")
            input_container.add_class("normal-mode")

            # ç§»é™¤æ‰€æœ‰å­ç»„ä»¶
            input_container.remove_children()

            # æ·»åŠ æ­£å¸¸çš„å‘½ä»¤è¾“å…¥ç»„ä»¶
            command_input = CommandInput()
            input_container.mount(command_input)

            # èšç„¦åˆ°è¾“å…¥æ¡†
            self._focus_current_input_widget()

        except Exception:
            self.logger.exception("æ¢å¤æ­£å¸¸è¾“å…¥ç»„ä»¶å¤±è´¥")
            # å¦‚æœæ¢å¤å¤±è´¥ï¼Œè‡³å°‘è¦é‡ç½®çŠ¶æ€
            self._mcp_mode = "normal"
            self._current_mcp_task_id = ""

    async def _send_mcp_response(self, task_id: str, *, params: bool | dict[str, Any]) -> None:
        """å‘é€ MCP å“åº”å¹¶å¤„ç†ç»“æœ"""
        output_container: Container | None = None

        try:
            # å…ˆè·å–è¾“å‡ºå®¹å™¨ï¼Œç¡®ä¿å¯ä»¥æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            output_container = self.query_one("#output-container", Container)

            # å‘é€ MCP å“åº”å¹¶å¤„ç†æµå¼å›å¤
            llm_client = self.get_llm_client()
            if hasattr(llm_client, "send_mcp_response"):
                success = await self._handle_mcp_response_stream(
                    task_id,
                    params=params,
                    output_container=output_container,
                    llm_client=llm_client,
                )
                if not success:
                    # å¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”å†…å®¹ï¼Œæ˜¾ç¤ºé»˜è®¤æ¶ˆæ¯
                    output_container.mount(OutputLine(_("ğŸ’¡ MCP response sent")))
            else:
                self.logger.error("å½“å‰å®¢æˆ·ç«¯ä¸æ”¯æŒ MCP å“åº”åŠŸèƒ½")
                output_container.mount(OutputLine(_("âŒ Current client does not support MCP response")))

        except Exception as e:
            self.logger.exception("å‘é€ MCP å“åº”å¤±è´¥")
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if output_container is not None:
                try:
                    error_message = self._format_error_message(e)
                    output_container.mount(
                        OutputLine(_("âŒ Failed to send MCP response: {error}").format(error=error_message)),
                    )
                except Exception:
                    # å¦‚æœè¿æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯éƒ½å¤±è´¥äº†ï¼Œè‡³å°‘è®°å½•æ—¥å¿—
                    self.logger.exception("æ— æ³•æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯")
        finally:
            # é‡ç½®å¤„ç†æ ‡å¿—ï¼Œä¸å†åœ¨è¿™é‡Œæ¢å¤è¾“å…¥ç•Œé¢
            self.processing = False

    async def _handle_mcp_response_stream(
        self,
        task_id: str,
        *,
        params: bool | dict[str, Any],
        output_container: Container,
        llm_client: LLMClientBase,
    ) -> bool:
        """å¤„ç† MCP å“åº”çš„æµå¼å›å¤"""
        if not isinstance(llm_client, HermesChatClient):
            self.logger.error("å½“å‰å®¢æˆ·ç«¯ä¸æ”¯æŒ MCP å“åº”åŠŸèƒ½")
            output_container.mount(OutputLine(_("âŒ Current client does not support MCP response")))
            return False

        # ä½¿ç”¨ç»Ÿä¸€çš„æµçŠ¶æ€ç®¡ç†ï¼Œä¸ _handle_command_stream ä¿æŒä¸€è‡´
        stream_state = self._init_stream_state()

        try:
            async for content in llm_client.send_mcp_response(task_id, params=params):
                if not content.strip():
                    continue

                stream_state["received_any_content"] = True
                current_time = asyncio.get_event_loop().time()

                # æ›´æ–°æœ€åæ”¶åˆ°å†…å®¹çš„æ—¶é—´
                if content.strip():
                    stream_state["last_content_time"] = current_time

                # æ£€æŸ¥è¶…æ—¶
                if self._check_timeouts(current_time, stream_state, output_container):
                    break

                # åˆ¤æ–­æ˜¯å¦ä¸º LLM è¾“å‡ºå†…å®¹
                tool_name, _cleaned_content = extract_mcp_tag(content)
                is_llm_output = tool_name is None

                # å¤„ç†å†…å®¹
                await self._process_stream_content(
                    content,
                    stream_state,
                    output_container,
                    is_llm_output=is_llm_output,
                )

                # æ»šåŠ¨åˆ°åº•éƒ¨
                await self._scroll_to_end()

            return stream_state["received_any_content"]
        except asyncio.CancelledError:
            output_container.mount(OutputLine(_("ğŸš« MCP response cancelled")))
            raise

    def _get_initial_agent(self) -> tuple[str, str]:
        """æ ¹æ®é…ç½®è·å–åˆå§‹æ™ºèƒ½ä½“ï¼Œåªåœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨"""
        default_app = self.config_manager.get_default_app()
        if default_app:
            # å¦‚æœé…ç½®äº†é»˜è®¤æ™ºèƒ½ä½“ï¼Œå°è¯•è·å–å¯¹åº”çš„åç§°
            # è¿™é‡Œå…ˆè¿”å› ID å’Œ ID ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆï¼Œåç»­åœ¨æ™ºèƒ½ä½“åˆ—è¡¨åŠ è½½åæ›´æ–°åç§°
            return (default_app, default_app)
        # å¦‚æœæ²¡æœ‰é…ç½®é»˜è®¤æ™ºèƒ½ä½“ï¼Œä½¿ç”¨æ™ºèƒ½é—®ç­”
        return ("", _("æ™ºèƒ½é—®ç­”"))

    def _reinitialize_agent_state(self) -> None:
        """é‡æ–°åˆå§‹åŒ–æ™ºèƒ½ä½“çŠ¶æ€ï¼Œç”¨äºåç«¯åˆ‡æ¢æ—¶"""
        # å°è¯•å¼‚æ­¥æ›´æ–°æ™ºèƒ½ä½“ä¿¡æ¯ï¼ˆå¦‚æœæ–°åç«¯æ”¯æŒæ™ºèƒ½ä½“åŠŸèƒ½ï¼‰
        self._initialize_default_agent()

    def _initialize_default_agent(self) -> None:
        """åˆå§‹åŒ–é»˜è®¤æ™ºèƒ½ä½“ï¼ŒåŒ…å«é…ç½®éªŒè¯"""
        # é¦–å…ˆéªŒè¯åç«¯é…ç½®
        validation_task = asyncio.create_task(self._validate_and_setup_configuration())
        self.background_tasks.add(validation_task)
        validation_task.add_done_callback(self._task_done_callback)

    async def _validate_and_setup_configuration(self) -> None:
        """éªŒè¯é…ç½®å¹¶è®¾ç½®æ™ºèƒ½ä½“ï¼Œå¦‚æœé…ç½®æ— æ•ˆåˆ™å¼¹å‡ºè®¾ç½®é¡µé¢"""
        try:
            # è·å–å½“å‰åç«¯é…ç½®
            backend = self.config_manager.get_backend()

            # éªŒè¯é…ç½®
            is_valid = await self._validate_backend_configuration(backend)

            if is_valid:
                # é…ç½®éªŒè¯é€šè¿‡ï¼Œç»§ç»­åˆå§‹åŒ–æ™ºèƒ½ä½“
                await self._setup_agent_after_validation()
            else:
                # é…ç½®éªŒè¯å¤±è´¥ï¼Œæ˜¾ç¤ºé€šçŸ¥å¹¶å¼¹å‡ºè®¾ç½®é¡µé¢
                self._show_config_validation_notification()
                await self._show_settings_for_config_fix()

        except Exception:
            self.logger.exception("é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
            # å³ä½¿éªŒè¯å‡ºé”™ï¼Œä¹Ÿå¼¹å‡ºè®¾ç½®é¡µé¢è®©ç”¨æˆ·æ‰‹åŠ¨é…ç½®
            self._show_config_validation_notification()
            await self._show_settings_for_config_fix()

    async def _validate_backend_configuration(self, backend: Backend) -> bool:
        """éªŒè¯åç«¯é…ç½®"""
        try:
            validator = APIValidator()

            if backend == Backend.OPENAI:
                # éªŒè¯ OpenAI é…ç½®
                base_url = self.config_manager.get_base_url()
                api_key = self.config_manager.get_api_key()
                model = self.config_manager.get_model()
                valid, _, _ = await validator.validate_llm_config(
                    endpoint=base_url,
                    api_key=api_key,
                    model=model,
                    timeout=10,
                )
                return valid

            if backend == Backend.EULERINTELLI:
                # éªŒè¯ openEuler Intelligence é…ç½®
                base_url = self.config_manager.get_eulerintelli_url()
                api_key = self.config_manager.get_eulerintelli_key()
                valid, _ = await validate_oi_connection(base_url, api_key)
                return valid

        except Exception:
            self.logger.exception("éªŒè¯åç«¯é…ç½®æ—¶å‘ç”Ÿé”™è¯¯")
            return False

        else:
            return False

    def _show_config_validation_notification(self) -> None:
        """æ˜¾ç¤ºé…ç½®éªŒè¯å¤±è´¥çš„é€šçŸ¥"""
        self.notify(
            _("Backend configuration validation failed, please check and modify"),
            title=_("Configuration Error"),
            severity="error",
            timeout=1,
        )

    async def _show_settings_for_config_fix(self) -> None:
        """å¼¹å‡ºè®¾ç½®é¡µé¢è®©ç”¨æˆ·ä¿®æ”¹é…ç½®"""
        try:
            # å¼¹å‡ºè®¾ç½®é¡µé¢
            settings_screen = SettingsScreen(self.config_manager, self.get_llm_client())
            self.push_screen(settings_screen)

            # ç­‰å¾…è®¾ç½®é¡µé¢é€€å‡º
            await self._wait_for_settings_screen_exit()

            # è®¾ç½®é¡µé¢é€€å‡ºåï¼Œé‡æ–°éªŒè¯é…ç½®
            backend = self.config_manager.get_backend()
            is_valid = await self._validate_backend_configuration(backend)

            if not is_valid:
                # å¦‚æœè¿˜æ˜¯æ— æ•ˆï¼Œé€’å½’è°ƒç”¨è‡ªå·±å†æ¬¡å¼¹å‡ºè®¾ç½®é¡µé¢
                self._show_config_validation_notification()
                await self._show_settings_for_config_fix()
            else:
                # é…ç½®éªŒè¯é€šè¿‡ï¼Œç»§ç»­åˆå§‹åŒ–æ™ºèƒ½ä½“
                await self._setup_agent_after_validation()

        except Exception:
            self.logger.exception("æ˜¾ç¤ºè®¾ç½®é¡µé¢æ—¶å‘ç”Ÿé”™è¯¯")

    async def _wait_for_settings_screen_exit(self) -> None:
        """ç­‰å¾…è®¾ç½®é¡µé¢é€€å‡º"""
        # ä½¿ç”¨äº‹ä»¶æ¥ç­‰å¾…è®¾ç½®é¡µé¢é€€å‡ºï¼Œè€Œä¸æ˜¯è½®è¯¢
        exit_event = asyncio.Event()

        # åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥ç›‘æ§å±å¹•æ ˆå˜åŒ–
        async def monitor_screen_stack() -> None:
            current_stack_length = len(self.screen_stack)
            while current_stack_length > 1:
                await asyncio.sleep(0.05)  # çŸ­æš‚ç­‰å¾…åé‡æ–°æ£€æŸ¥
                current_stack_length = len(self.screen_stack)
            exit_event.set()

        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        monitor_task = asyncio.create_task(monitor_screen_stack())

        # ç­‰å¾…é€€å‡ºäº‹ä»¶
        try:
            await exit_event.wait()
        finally:
            # å–æ¶ˆç›‘æ§ä»»åŠ¡
            if not monitor_task.done():
                monitor_task.cancel()

    async def _setup_agent_after_validation(self) -> None:
        """é…ç½®éªŒè¯é€šè¿‡åè®¾ç½®æ™ºèƒ½ä½“"""
        try:
            # å¦‚æœå½“å‰æ™ºèƒ½ä½“æ˜¯åŸºäº default_app é…ç½®çš„ï¼Œä¸”éœ€è¦æ›´æ–°åç§°
            app_id, name = self.current_agent
            if app_id and app_id == name:  # è¿™è¡¨ç¤ºæˆ‘ä»¬åœ¨ _get_initial_agent ä¸­ä½¿ç”¨äº†ä¸´æ—¶æ–¹æ¡ˆ
                # å¼‚æ­¥è·å–æ™ºèƒ½ä½“ä¿¡æ¯å¹¶æ›´æ–°åç§°
                await self._update_agent_name_from_list()
        except Exception:
            self.logger.exception("è®¾ç½®æ™ºèƒ½ä½“æ—¶å‘ç”Ÿé”™è¯¯")

    async def _update_agent_name_from_list(self) -> None:
        """ä»æ™ºèƒ½ä½“åˆ—è¡¨ä¸­æ›´æ–°å½“å‰æ™ºèƒ½ä½“çš„åç§°"""
        try:
            llm_client = self.get_llm_client()
            if hasattr(llm_client, "get_available_agents"):
                available_agents = await llm_client.get_available_agents()  # type: ignore[attr-defined]
                app_id, _name = self.current_agent

                # æŸ¥æ‰¾åŒ¹é…çš„æ™ºèƒ½ä½“
                agent_found = False
                for agent in available_agents:
                    if hasattr(agent, "app_id") and hasattr(agent, "name") and agent.app_id == app_id:
                        # æ›´æ–°æ™ºèƒ½ä½“ä¿¡æ¯
                        self.current_agent = (agent.app_id, agent.name)
                        # è®¾ç½®æ™ºèƒ½ä½“åˆ°å®¢æˆ·ç«¯
                        if hasattr(llm_client, "set_current_agent"):
                            llm_client.set_current_agent(app_id)  # type: ignore[attr-defined]
                        agent_found = True
                        break

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ™ºèƒ½ä½“ï¼Œè¯´æ˜é…ç½®çš„é»˜è®¤æ™ºèƒ½ä½“IDå·²æ— æ•ˆ
                if not agent_found and app_id:
                    self.logger.warning("é…ç½®çš„é»˜è®¤æ™ºèƒ½ä½“ '%s' ä¸å­˜åœ¨ï¼Œå›é€€åˆ°æ™ºèƒ½é—®ç­”å¹¶æ¸…ç†é…ç½®", app_id)
                    # å›é€€åˆ°æ™ºèƒ½é—®ç­”
                    self.current_agent = ("", _("æ™ºèƒ½é—®ç­”"))
                    # æ¸…ç†é…ç½®ä¸­çš„æ— æ•ˆID
                    self.config_manager.set_default_app("")
                    # ç¡®ä¿å®¢æˆ·ç«¯ä¹Ÿåˆ‡æ¢åˆ°æ™ºèƒ½é—®ç­”
                    if hasattr(llm_client, "set_current_agent"):
                        llm_client.set_current_agent("")  # type: ignore[attr-defined]
        except (AttributeError, OSError, ValueError, RuntimeError) as e:
            self.logger.warning("æ— æ³•æ›´æ–°æ™ºèƒ½ä½“åç§°: %s", str(e))
